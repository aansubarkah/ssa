{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "7644c"
   },
   "source": [
    "# Batch Convert PDF Tables to Excel\n",
    "\n",
    "This notebook scans the current directory for all PDF files, processes each PDF page by page, extracts tables using Google Vision API, and saves each PDF as a separate Excel file with '_extracted.xlsx' suffix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "3a667"
   },
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "1. Install required packages if not already installed\n",
    "2. Set your Google API key\n",
    "3. Configure the prompt for table extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellUniqueIdByVincent": "a2efd"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "#^pip install google-genai pdf2image pillow pandas openpyxl tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "08580"
   },
   "source": [
    "## API Key Configuration\n",
    "\n",
    "**IMPORTANT:** Replace the API_KEY below with your actual key from https://aistudio.google.com/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellUniqueIdByVincent": "1372e"
   },
   "outputs": [],
   "source": [
    "API_KEY = 'AIzaSyDBhCAMcISchXzLzkyWN3uI_ZvNKBDEP6Q'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "73b1e"
   },
   "source": [
    "## Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellUniqueIdByVincent": "330c6"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "from tqdm.notebook import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "from typing import List, Any\n",
    "\n",
    "# Initialize the client\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "21529"
   },
   "source": [
    "## Define Data Models and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellUniqueIdByVincent": "e365a"
   },
   "outputs": [],
   "source": [
    "# Define the data model for table rows\n",
    "class TableRow(BaseModel):\n",
    "    row_data: List[str]  # Each cell in the row as a string\n",
    "\n",
    "class TableData(BaseModel):\n",
    "    headers: List[str]  # Column headers\n",
    "    rows: List[TableRow]  # Table rows\n",
    "    page_info: str  # Any additional page information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellUniqueIdByVincent": "a6dfa"
   },
   "outputs": [],
   "source": [
    "# Prompt for table extraction\n",
    "TABLE_EXTRACTION_PROMPT = '''\n",
    "Analyze this image and extract all table data found on this page.\n",
    "\n",
    "Please:\n",
    "1. Identify all tables on the page\n",
    "2. Extract column headers (if any)\n",
    "3. Extract all row data, preserving the structure\n",
    "4. If there are multiple tables, combine them or note their separation\n",
    "5. Include any relevant page information (title, date, etc.)\n",
    "\n",
    "Return the data in the specified JSON format with:\n",
    "- headers: list of column headers\n",
    "- rows: list of table rows, where each row contains a list of cell values\n",
    "- page_info: any additional context about the page\n",
    "\n",
    "If no table is found, return empty headers and rows arrays.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "1226d"
   },
   "source": [
    "## PDF Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellUniqueIdByVincent": "103e8"
   },
   "outputs": [],
   "source": [
    "def get_pdf_files_in_directory(directory=\".\"):\n",
    "    \"\"\"\n",
    "    Get all PDF files in the specified directory\n",
    "    \n",
    "    Args:\n",
    "        directory: Directory to search for PDF files (default current directory)\n",
    "    \n",
    "    Returns:\n",
    "        List of PDF file paths\n",
    "    \"\"\"\n",
    "    pdf_pattern = os.path.join(directory, \"*.pdf\")\n",
    "    pdf_files = glob.glob(pdf_pattern)\n",
    "    return [os.path.basename(pdf) for pdf in pdf_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellUniqueIdByVincent": "0e1af"
   },
   "outputs": [],
   "source": [
    "def get_output_filename(pdf_filename):\n",
    "    \"\"\"\n",
    "    Generate output Excel filename from PDF filename\n",
    "    \n",
    "    Args:\n",
    "        pdf_filename: Original PDF filename (e.g., 'HSP.pdf')\n",
    "    \n",
    "    Returns:\n",
    "        Excel filename with '_extracted.xlsx' suffix (e.g., 'HSP_extracted.xlsx')\n",
    "    \"\"\"\n",
    "    base_name = os.path.splitext(pdf_filename)[0]\n",
    "    return f\"{base_name}_extracted.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellUniqueIdByVincent": "0e93b"
   },
   "outputs": [],
   "source": [
    "def convert_pdf_to_images(pdf_path, dpi=200):\n",
    "    \"\"\"\n",
    "    Convert PDF pages to images\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        dpi: Resolution for conversion (higher = better quality, larger file)\n",
    "    \n",
    "    Returns:\n",
    "        List of PIL Image objects\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"  Converting PDF to images with DPI: {dpi}\")\n",
    "        images = convert_from_path(pdf_path, dpi=dpi)\n",
    "        print(f\"  Successfully converted {len(images)} pages\")\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        print(f\"  Error converting PDF: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellUniqueIdByVincent": "3de56"
   },
   "outputs": [],
   "source": [
    "def extract_table_from_image(image, page_num, pdf_name):\n",
    "    \"\"\"\n",
    "    Extract table data from a single page image using Google Vision API\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        page_num: Page number for reference\n",
    "        pdf_name: PDF filename for reference\n",
    "    \n",
    "    Returns:\n",
    "        TableData object or None if extraction fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert PIL image to bytes\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        image.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr = img_byte_arr.getvalue()\n",
    "        \n",
    "        # Call Google Vision API\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash-lite',\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.2,\n",
    "                response_mime_type='application/json',\n",
    "                response_schema=TableData\n",
    "            ),\n",
    "            contents=[\n",
    "                types.Part.from_bytes(\n",
    "                    data=img_byte_arr,\n",
    "                    mime_type='image/png'\n",
    "                ),\n",
    "                TABLE_EXTRACTION_PROMPT\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        table_data: TableData = response.parsed\n",
    "        print(f\"    Page {page_num}: Extracted {len(table_data.rows)} rows\")\n",
    "        return table_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Error extracting table from page {page_num}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "faeb0"
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Batch Convert PDF Tables to Excel\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook scans the current directory for all PDF files, processes each PDF page by page, extracts tables using Google Vision API, and saves each PDF as a separate Excel file with '_extracted.xlsx' suffix.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Setup and Configuration\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Install required packages if not already installed\\n\",\n",
    "    \"2. Set your Google API key\\n\",\n",
    "    \"3. Configure the prompt for table extraction\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Install required packages\\n\",\n",
    "    \"#!pip install google-genai pdf2image pillow pandas openpyxl tqdm\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## API Key Configuration\\n\",\n",
    "    \"\\n\",\n",
    "    \"**IMPORTANT:** Replace the API_KEY below with your actual key from https://aistudio.google.com/apikey\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"API_KEY = 'AIzaSyDBhCAMcISchXzLzkyWN3uI_ZvNKBDEP6Q'\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Import Libraries and Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from google import genai\\n\",\n",
    "    \"from google.genai import types\\n\",\n",
    "    \"from pydantic import BaseModel\\n\",\n",
    "    \"from tqdm.notebook import tqdm\\n\",\n",
    "    \"from pdf2image import convert_from_path\\n\",\n",
    "    \"from PIL import Image\\n\",\n",
    "    \"\\n\",\n",
    "    \"import io\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import glob\\n\",\n",
    "    \"from typing import List, Any\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize the client\\n\",\n",
    "    \"client = genai.Client(api_key=API_KEY)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Define Data Models and Prompts\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define the data model for table rows\\n\",\n",
    "    \"class TableRow(BaseModel):\\n\",\n",
    "    \"    row_data: List[str]  # Each cell in the row as a string\\n\",\n",
    "    \"\\n\",\n",
    "    \"class TableData(BaseModel):\\n\",\n",
    "    \"    headers: List[str]  # Column headers\\n\",\n",
    "    \"    rows: List[TableRow]  # Table rows\\n\",\n",
    "    \"    page_info: str  # Any additional page information\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Prompt for table extraction\\n\",\n",
    "    \"TABLE_EXTRACTION_PROMPT = '''\\n\",\n",
    "    \"Analyze this image and extract all table data found on this page.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Please:\\n\",\n",
    "    \"1. Identify all tables on the page\\n\",\n",
    "    \"2. Extract column headers (if any)\\n\",\n",
    "    \"3. Extract all row data, preserving the structure\\n\",\n",
    "    \"4. If there are multiple tables, combine them or note their separation\\n\",\n",
    "    \"5. Include any relevant page information (title, date, etc.)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Return the data in the specified JSON format with:\\n\",\n",
    "    \"- headers: list of column headers\\n\",\n",
    "    \"- rows: list of table rows, where each row contains a list of cell values\\n\",\n",
    "    \"- page_info: any additional context about the page\\n\",\n",
    "    \"\\n\",\n",
    "    \"If no table is found, return empty headers and rows arrays.\\n\",\n",
    "    \"'''\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## PDF Processing Functions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def get_pdf_files_in_directory(directory=\\\".\\\"):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Get all PDF files in the specified directory\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        directory: Directory to search for PDF files (default current directory)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        List of PDF file paths\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    pdf_pattern = os.path.join(directory, \\\"*.pdf\\\")\\n\",\n",
    "    \"    pdf_files = glob.glob(pdf_pattern)\\n\",\n",
    "    \"    return [os.path.basename(pdf) for pdf in pdf_files]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def get_output_filename(pdf_filename):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Generate output Excel filename from PDF filename\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        pdf_filename: Original PDF filename (e.g., 'HSP.pdf')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        Excel filename with '_extracted.xlsx' suffix (e.g., 'HSP_extracted.xlsx')\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    base_name = os.path.splitext(pdf_filename)[0]\\n\",\n",
    "    \"    return f\\\"{base_name}_extracted.xlsx\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def convert_pdf_to_images(pdf_path, dpi=200):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Convert PDF pages to images\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        pdf_path: Path to the PDF file\\n\",\n",
    "    \"        dpi: Resolution for conversion (higher = better quality, larger file)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        List of PIL Image objects\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        print(f\\\"  Converting PDF to images with DPI: {dpi}\\\")\\n\",\n",
    "    \"        images = convert_from_path(pdf_path, dpi=dpi)\\n\",\n",
    "    \"        print(f\\\"  Successfully converted {len(images)} pages\\\")\\n\",\n",
    "    \"        return images\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"  Error converting PDF: {e}\\\")\\n\",\n",
    "    \"        return []\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def extract_table_from_image(image, page_num, pdf_name):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Extract table data from a single page image using Google Vision API\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        image: PIL Image object\\n\",\n",
    "    \"        page_num: Page number for reference\\n\",\n",
    "    \"        pdf_name: PDF filename for reference\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        TableData object or None if extraction fails\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # Convert PIL image to bytes\\n\",\n",
    "    \"        img_byte_arr = io.BytesIO()\\n\",\n",
    "    \"        image.save(img_byte_arr, format='PNG')\\n\",\n",
    "    \"        img_byte_arr = img_byte_arr.getvalue()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Call Google Vision API\\n\",\n",
    "    \"        response = client.models.generate_content(\\n\",\n",
    "    \"            model='gemini-2.0-flash-lite',\\n\",\n",
    "    \"            config=types.GenerateContentConfig(\\n\",\n",
    "    \"                temperature=0.2,\\n\",\n",
    "    \"                response_mime_type='application/json',\\n\",\n",
    "    \"                response_schema=TableData\\n\",\n",
    "    \"            ),\\n\",\n",
    "    \"            contents=[\\n\",\n",
    "    \"                types.Part.from_bytes(\\n\",\n",
    "    \"                    data=img_byte_arr,\\n\",\n",
    "    \"                    mime_type='image/png'\\n\",\n",
    "    \"                ),\\n\",\n",
    "    \"                TABLE_EXTRACTION_PROMPT\\n\",\n",
    "    \"            ]\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        table_data: TableData = response.parsed\\n\",\n",
    "    \"        print(f\\\"    Page {page_num}: Extracted {len(table_data.rows)} rows\\\")\\n\",\n",
    "    \"        return table_data\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"    Error extracting table from page {page_num}: {e}\\\")\\n\",\n",
    "    \"        return None\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def table_data_to_dataframe(table_data, page_num, pdf_name):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Convert TableData to pandas DataFrame with column length handling\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        if not table_data or not table_data.rows:\\n\",\n",
    "    \"            print(f\\\"    Page {page_num}: No table data found\\\")\\n\",\n",
    "    \"            return None\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Convert rows to list of lists\\n\",\n",
    "    \"        rows_data = [row.row_data for row in table_data.rows]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Handle column mismatch - find the maximum number of columns\\n\",\n",
    "    \"        max_columns = max(len(row) for row in rows_data)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Ensure all rows have the same length\\n\",\n",
    "    \"        for i, row in enumerate(rows_data):\\n\",\n",
    "    \"            if len(row) < max_columns:\\n\",\n",
    "    \"                # Pad shorter rows with empty strings\\n\",\n",
    "    \"                rows_data[i] = row + [''] * (max_columns - len(row))\\n\",\n",
    "    \"            elif len(row) > max_columns:\\n\",\n",
    "    \"                # Truncate longer rows (less likely but possible)\\n\",\n",
    "    \"                rows_data[i] = row[:max_columns]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Create headers - if we have headers, ensure they match max_columns\\n\",\n",
    "    \"        if table_data.headers:\\n\",\n",
    "    \"            headers = table_data.headers.copy()\\n\",\n",
    "    \"            if len(headers) < max_columns:\\n\",\n",
    "    \"                headers += [f'Column_{i}' for i in range(len(headers), max_columns)]\\n\",\n",
    "    \"            elif len(headers) > max_columns:\\n\",\n",
    "    \"                headers = headers[:max_columns]\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            headers = [f'Column_{i}' for i in range(max_columns)]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Create DataFrame\\n\",\n",
    "    \"        df = pd.DataFrame(rows_data, columns=headers)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Add metadata\\n\",\n",
    "    \"        df['page_number'] = page_num\\n\",\n",
    "    \"        df['source_pdf'] = pdf_name\\n\",\n",
    "    \"        if table_data.page_info:\\n\",\n",
    "    \"            df['page_info'] = table_data.page_info\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return df\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"    Error converting table data to DataFrame for page {page_num}: {e}\\\")\\n\",\n",
    "    \"        return None\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def old_table_data_to_dataframe(table_data, page_num, pdf_name):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Convert TableData to pandas DataFrame\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        table_data: TableData object\\n\",\n",
    "    \"        page_num: Page number for reference\\n\",\n",
    "    \"        pdf_name: PDF filename for reference\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        pandas DataFrame or None if conversion fails\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        if not table_data or not table_data.rows:\\n\",\n",
    "    \"            print(f\\\"    Page {page_num}: No table data found\\\")\\n\",\n",
    "    \"            return None\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Convert rows to list of lists\\n\",\n",
    "    \"        rows_data = [row.row_data for row in table_data.rows]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Create DataFrame\\n\",\n",
    "    \"        if table_data.headers:\\n\",\n",
    "    \"            df = pd.DataFrame(rows_data, columns=table_data.headers)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            df = pd.DataFrame(rows_data)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Add metadata\\n\",\n",
    "    \"        df['page_number'] = page_num\\n\",\n",
    "    \"        df['source_pdf'] = pdf_name\\n\",\n",
    "    \"        if table_data.page_info:\\n\",\n",
    "    \"            df['page_info'] = table_data.page_info\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return df\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"    Error converting table data to DataFrame for page {page_num}: {e}\\\")\\n\",\n",
    "    \"        return None\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Single PDF Processing Function\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def process_single_pdf_to_excel(pdf_path, output_path, dpi=200):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Process a single PDF and create Excel file with separate sheets for each page\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        pdf_path: Path to the PDF file\\n\",\n",
    "    \"        output_path: Path for the output Excel file\\n\",\n",
    "    \"        dpi: Resolution for PDF to image conversion\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        True if successful, False otherwise\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    pdf_name = os.path.basename(pdf_path)\\n\",\n",
    "    \"    print(f\\\"\\\\nProcessing: {pdf_name}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Convert PDF to images\\n\",\n",
    "    \"    images = convert_pdf_to_images(pdf_path, dpi)\\n\",\n",
    "    \"    if not images:\\n\",\n",
    "    \"        print(f\\\"  Failed to convert {pdf_name} to images\\\")\\n\",\n",
    "    \"        return False\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Process each page\\n\",\n",
    "    \"    all_dataframes = {}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, image in enumerate(tqdm(images, desc=f\\\"  Processing {pdf_name}\\\")):\\n\",\n",
    "    \"        page_num = i + 1\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Extract table data\\n\",\n",
    "    \"        table_data = extract_table_from_image(image, page_num, pdf_name)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if table_data:\\n\",\n",
    "    \"            # Convert to DataFrame\\n\",\n",
    "    \"            df = table_data_to_dataframe(table_data, page_num, pdf_name)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if df is not None and not df.empty:\\n\",\n",
    "    \"                sheet_name = f\\\"Page_{page_num}\\\"\\n\",\n",
    "    \"                all_dataframes[sheet_name] = df\\n\",\n",
    "    \"                print(f\\\"    Page {page_num}: Added {len(df)} rows to sheet '{sheet_name}'\\\")\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                print(f\\\"    Page {page_num}: No valid data extracted\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"    Page {page_num}: Failed to extract table data\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save to Excel\\n\",\n",
    "    \"    if all_dataframes:\\n\",\n",
    "    \"        print(f\\\"  Saving {len(all_dataframes)} sheets to {output_path}\\\")\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\\n\",\n",
    "    \"                for sheet_name, df in all_dataframes.items():\\n\",\n",
    "    \"                    df.to_excel(writer, sheet_name=sheet_name, index=False)\\n\",\n",
    "    \"            print(f\\\"  Successfully saved: {output_path}\\\")\\n\",\n",
    "    \"            return True\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            print(f\\\"  Error saving Excel file: {e}\\\")\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(f\\\"  No data extracted from {pdf_name}\\\")\\n\",\n",
    "    \"        return False\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Batch Processing Function\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def batch_process_pdfs(directory=\\\".\\\", dpi=200):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Process all PDF files in the directory\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        directory: Directory to search for PDF files\\n\",\n",
    "    \"        dpi: Resolution for PDF to image conversion\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        Dictionary with processing results\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Find all PDF files\\n\",\n",
    "    \"    pdf_files = get_pdf_files_in_directory(directory)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not pdf_files:\\n\",\n",
    "    \"        print(\\\"No PDF files found in the current directory.\\\")\\n\",\n",
    "    \"        return {}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Found {len(pdf_files)} PDF files:\\\")\\n\",\n",
    "    \"    for pdf in pdf_files:\\n\",\n",
    "    \"        print(f\\\"  - {pdf}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Process each PDF\\n\",\n",
    "    \"    results = {\\n\",\n",
    "    \"        'successful': [],\\n\",\n",
    "    \"        'failed': [],\\n\",\n",
    "    \"        'total': len(pdf_files)\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n{'='*50}\\\")\\n\",\n",
    "    \"    print(\\\"STARTING BATCH PROCESSING\\\")\\n\",\n",
    "    \"    print(f\\\"{'='*50}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, pdf_file in enumerate(pdf_files, 1):\\n\",\n",
    "    \"        print(f\\\"\\\\n[{i}/{len(pdf_files)}] Processing: {pdf_file}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Generate output filename\\n\",\n",
    "    \"        output_file = get_output_filename(pdf_file)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Check if output already exists\\n\",\n",
    "    \"        if os.path.exists(output_file):\\n\",\n",
    "    \"            print(f\\\"  Output file {output_file} already exists. Skipping...\\\")\\n\",\n",
    "    \"            results['successful'].append({'pdf': pdf_file, 'output': output_file, 'status': 'skipped'})\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Process the PDF\\n\",\n",
    "    \"        success = process_single_pdf_to_excel(pdf_file, output_file, dpi)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if success:\\n\",\n",
    "    \"            results['successful'].append({'pdf': pdf_file, 'output': output_file, 'status': 'processed'})\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            results['failed'].append({'pdf': pdf_file, 'output': output_file, 'error': 'processing_failed'})\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Execute Batch Processing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Execute batch processing\\n\",\n",
    "    \"print(\\\"Starting batch PDF processing...\\\")\\n\",\n",
    "    \"print(\\\"This will process all PDF files in the current directory.\\\")\\n\",\n",
    "    \"print(\\\"Each PDF will be converted to an Excel file with '_extracted.xlsx' suffix.\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Run batch processing\\n\",\n",
    "    \"results = batch_process_pdfs(directory=\\\".\\\", dpi=200)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Print summary\\n\",\n",
    "    \"if results:\\n\",\n",
    "    \"    print(f\\\"\\\\n{'='*50}\\\")\\n\",\n",
    "    \"    print(\\\"BATCH PROCESSING COMPLETE\\\")\\n\",\n",
    "    \"    print(f\\\"{'='*50}\\\")\\n\",\n",
    "    \"    print(f\\\"Total files processed: {results['total']}\\\")\\n\",\n",
    "    \"    print(f\\\"Successful: {len(results['successful'])}\\\")\\n\",\n",
    "    \"    print(f\\\"Failed: {len(results['failed'])}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if results['successful']:\\n\",\n",
    "    \"        print(\\\"\\\\nSuccessfully processed:\\\")\\n\",\n",
    "    \"        for item in results['successful']:\\n\",\n",
    "    \"            status = item['status']\\n\",\n",
    "    \"            print(f\\\"  ✓ {item['pdf']} → {item['output']} ({status})\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if results['failed']:\\n\",\n",
    "    \"        print(\\\"\\\\nFailed to process:\\\")\\n\",\n",
    "    \"        for item in results['failed']:\\n\",\n",
    "    \"            print(f\\\"  ✗ {item['pdf']} (Error: {item['error']})\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No PDF files found to process.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Optional: Preview Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Optional: Preview all generated Excel files\\n\",\n",
    "    \"excel_files = glob.glob(\\\"*_extracted.xlsx\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if excel_files:\\n\",\n",
    "    \"    print(f\\\"Found {len(excel_files)} generated Excel files:\\\\n\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for excel_file in excel_files:\\n\",\n",
    "    \"        print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"        print(f\\\"File: {excel_file}\\\")\\n\",\n",
    "    \"        print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            excel_data = pd.ExcelFile(excel_file)\\n\",\n",
    "    \"            print(f\\\"Contains {len(excel_data.sheet_names)} sheets:\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            for sheet_name in excel_data.sheet_names[:5]:  # Show first 5 sheets\\n\",\n",
    "    \"                df = pd.read_excel(excel_file, sheet_name=sheet_name)\\n\",\n",
    "    \"                print(f\\\"\\\\n  {sheet_name}: {len(df)} rows, {len(df.columns)} columns\\\")\\n\",\n",
    "    \"                if len(df.columns) > 0:\\n\",\n",
    "    \"                    print(f\\\"  Columns: {list(df.columns)[:5]}...\\\")  # Show first 5 columns\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                # Show first row if data exists\\n\",\n",
    "    \"                if len(df) > 0:\\n\",\n",
    "    \"                    print(f\\\"  Sample data: {df.iloc[0].tolist()[:3]}...\\\")  # First 3 cells\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if len(excel_data.sheet_names) > 5:\\n\",\n",
    "    \"                print(f\\\"\\\\n  ... and {len(excel_data.sheet_names) - 5} more sheets\\\")\\n\",\n",
    "    \"                \\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            print(f\\\"Error reading {excel_file}: {e}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(\\\"\\\\n\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No Excel files with '_extracted.xlsx' suffix found.\\\")\\n\",\n",
    "    \"    print(\\\"Please run the batch processing cell above first.\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "8b65e"
   },
   "outputs": [],
   "source": [
    "def old_table_data_to_dataframe(table_data, page_num, pdf_name):\n",
    "    \"\"\"\n",
    "    Convert TableData to pandas DataFrame\n",
    "    \n",
    "    Args:\n",
    "        table_data: TableData object\n",
    "        page_num: Page number for reference\n",
    "        pdf_name: PDF filename for reference\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame or None if conversion fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not table_data or not table_data.rows:\n",
    "            print(f\"    Page {page_num}: No table data found\")\n",
    "            return None\n",
    "        \n",
    "        # Convert rows to list of lists\n",
    "        rows_data = [row.row_data for row in table_data.rows]\n",
    "        \n",
    "        # Create DataFrame\n",
    "        if table_data.headers:\n",
    "            df = pd.DataFrame(rows_data, columns=table_data.headers)\n",
    "        else:\n",
    "            df = pd.DataFrame(rows_data)\n",
    "        \n",
    "        # Add metadata\n",
    "        df['page_number'] = page_num\n",
    "        df['source_pdf'] = pdf_name\n",
    "        if table_data.page_info:\n",
    "            df['page_info'] = table_data.page_info\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Error converting table data to DataFrame for page {page_num}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "1b4dc"
   },
   "source": [
    "## Single PDF Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellUniqueIdByVincent": "c4552"
   },
   "outputs": [],
   "source": [
    "def process_single_pdf_to_excel(pdf_path, output_path, dpi=200):\n",
    "    \"\"\"\n",
    "    Process a single PDF and create Excel file with separate sheets for each page\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        output_path: Path for the output Excel file\n",
    "        dpi: Resolution for PDF to image conversion\n",
    "    \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    pdf_name = os.path.basename(pdf_path)\n",
    "    print(f\"\\nProcessing: {pdf_name}\")\n",
    "    \n",
    "    # Convert PDF to images\n",
    "    images = convert_pdf_to_images(pdf_path, dpi)\n",
    "    if not images:\n",
    "        print(f\"  Failed to convert {pdf_name} to images\")\n",
    "        return False\n",
    "    \n",
    "    # Process each page\n",
    "    all_dataframes = {}\n",
    "    \n",
    "    for i, image in enumerate(tqdm(images, desc=f\"  Processing {pdf_name}\")):\n",
    "        page_num = i + 1\n",
    "        \n",
    "        # Extract table data\n",
    "        table_data = extract_table_from_image(image, page_num, pdf_name)\n",
    "        \n",
    "        if table_data:\n",
    "            # Convert to DataFrame\n",
    "            df = table_data_to_dataframe(table_data, page_num, pdf_name)\n",
    "            \n",
    "            if df is not None and not df.empty:\n",
    "                sheet_name = f\"Page_{page_num}\"\n",
    "                all_dataframes[sheet_name] = df\n",
    "                print(f\"    Page {page_num}: Added {len(df)} rows to sheet '{sheet_name}'\")\n",
    "            else:\n",
    "                print(f\"    Page {page_num}: No valid data extracted\")\n",
    "        else:\n",
    "            print(f\"    Page {page_num}: Failed to extract table data\")\n",
    "    \n",
    "    # Save to Excel\n",
    "    if all_dataframes:\n",
    "        print(f\"  Saving {len(all_dataframes)} sheets to {output_path}\")\n",
    "        try:\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                for sheet_name, df in all_dataframes.items():\n",
    "                    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            print(f\"  Successfully saved: {output_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"  Error saving Excel file: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"  No data extracted from {pdf_name}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "2526a"
   },
   "source": [
    "## Batch Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellUniqueIdByVincent": "ad866"
   },
   "outputs": [],
   "source": [
    "def batch_process_pdfs(directory=\".\", dpi=200):\n",
    "    \"\"\"\n",
    "    Process all PDF files in the directory\n",
    "    \n",
    "    Args:\n",
    "        directory: Directory to search for PDF files\n",
    "        dpi: Resolution for PDF to image conversion\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with processing results\n",
    "    \"\"\"\n",
    "    # Find all PDF files\n",
    "    pdf_files = get_pdf_files_in_directory(directory)\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(\"No PDF files found in the current directory.\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "    for pdf in pdf_files:\n",
    "        print(f\"  - {pdf}\")\n",
    "    \n",
    "    # Process each PDF\n",
    "    results = {\n",
    "        'successful': [],\n",
    "        'failed': [],\n",
    "        'total': len(pdf_files)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"STARTING BATCH PROCESSING\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for i, pdf_file in enumerate(pdf_files, 1):\n",
    "        print(f\"\\n[{i}/{len(pdf_files)}] Processing: {pdf_file}\")\n",
    "        \n",
    "        # Generate output filename\n",
    "        output_file = get_output_filename(pdf_file)\n",
    "        \n",
    "        # Check if output already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"  Output file {output_file} already exists. Skipping...\")\n",
    "            results['successful'].append({'pdf': pdf_file, 'output': output_file, 'status': 'skipped'})\n",
    "            continue\n",
    "        \n",
    "        # Process the PDF\n",
    "        success = process_single_pdf_to_excel(pdf_file, output_file, dpi)\n",
    "        \n",
    "        if success:\n",
    "            results['successful'].append({'pdf': pdf_file, 'output': output_file, 'status': 'processed'})\n",
    "        else:\n",
    "            results['failed'].append({'pdf': pdf_file, 'output': output_file, 'error': 'processing_failed'})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "19eeb"
   },
   "source": [
    "## Execute Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "b907b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch PDF processing...\n",
      "This will process all PDF files in the current directory.\n",
      "Each PDF will be converted to an Excel file with '_extracted.xlsx' suffix.\n",
      "\n",
      "Found 1 PDF files:\n",
      "  - HSP.pdf\n",
      "\n",
      "==================================================\n",
      "STARTING BATCH PROCESSING\n",
      "==================================================\n",
      "\n",
      "[1/1] Processing: HSP.pdf\n",
      "\n",
      "Processing: HSP.pdf\n",
      "  Converting PDF to images with DPI: 200\n",
      "  Successfully converted 38 pages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d944cd044c41e290a913ebf476341e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Processing HSP.pdf:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Page 1: Extracted 0 rows\n",
      "    Page 1: No table data found\n",
      "    Page 1: No valid data extracted\n",
      "    Page 2: Extracted 0 rows\n",
      "    Page 2: No table data found\n",
      "    Page 2: No valid data extracted\n",
      "    Page 3: Extracted 1 rows\n",
      "    Page 3: Added 1 rows to sheet 'Page_3'\n",
      "    Page 4: Extracted 15 rows\n",
      "    Page 4: Added 15 rows to sheet 'Page_4'\n",
      "    Page 5: Extracted 79 rows\n",
      "    Page 5: Added 79 rows to sheet 'Page_5'\n",
      "    Page 6: Extracted 86 rows\n",
      "    Page 6: Added 86 rows to sheet 'Page_6'\n",
      "    Page 7: Extracted 84 rows\n",
      "    Page 7: Added 84 rows to sheet 'Page_7'\n",
      "    Page 8: Extracted 83 rows\n",
      "    Page 8: Added 83 rows to sheet 'Page_8'\n",
      "    Page 9: Extracted 68 rows\n",
      "    Page 9: Added 68 rows to sheet 'Page_9'\n",
      "    Page 10: Extracted 84 rows\n",
      "    Page 10: Added 84 rows to sheet 'Page_10'\n",
      "    Page 11: Extracted 42 rows\n",
      "    Page 11: Added 42 rows to sheet 'Page_11'\n",
      "    Page 12: Extracted 52 rows\n",
      "    Page 12: Added 52 rows to sheet 'Page_12'\n",
      "    Page 13: Extracted 79 rows\n",
      "    Page 13: Added 79 rows to sheet 'Page_13'\n",
      "    Page 14: Extracted 80 rows\n",
      "    Page 14: Added 80 rows to sheet 'Page_14'\n",
      "    Page 15: Extracted 62 rows\n",
      "    Page 15: Added 62 rows to sheet 'Page_15'\n",
      "    Page 16: Extracted 67 rows\n",
      "    Page 16: Added 67 rows to sheet 'Page_16'\n",
      "    Page 17: Extracted 75 rows\n",
      "    Page 17: Added 75 rows to sheet 'Page_17'\n",
      "    Page 18: Extracted 77 rows\n",
      "    Page 18: Added 77 rows to sheet 'Page_18'\n",
      "    Page 19: Extracted 78 rows\n",
      "    Page 19: Added 78 rows to sheet 'Page_19'\n",
      "    Page 20: Extracted 75 rows\n",
      "    Page 20: Added 75 rows to sheet 'Page_20'\n"
     ]
    }
   ],
   "source": [
    "# Execute batch processing\n",
    "print(\"Starting batch PDF processing...\")\n",
    "print(\"This will process all PDF files in the current directory.\")\n",
    "print(\"Each PDF will be converted to an Excel file with '_extracted.xlsx' suffix.\\n\")\n",
    "\n",
    "# Run batch processing\n",
    "results = batch_process_pdfs(directory=\".\", dpi=200)\n",
    "\n",
    "# Print summary\n",
    "if results:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"BATCH PROCESSING COMPLETE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total files processed: {results['total']}\")\n",
    "    print(f\"Successful: {len(results['successful'])}\")\n",
    "    print(f\"Failed: {len(results['failed'])}\")\n",
    "    \n",
    "    if results['successful']:\n",
    "        print(\"\\nSuccessfully processed:\")\n",
    "        for item in results['successful']:\n",
    "            status = item['status']\n",
    "            print(f\"  ✓ {item['pdf']} → {item['output']} ({status})\")\n",
    "    \n",
    "    if results['failed']:\n",
    "        print(\"\\nFailed to process:\")\n",
    "        for item in results['failed']:\n",
    "            print(f\"  ✗ {item['pdf']} (Error: {item['error']})\")\n",
    "else:\n",
    "    print(\"No PDF files found to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "4b21e"
   },
   "source": [
    "## Optional: Preview Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "ebb8f"
   },
   "outputs": [],
   "source": [
    "# Optional: Preview all generated Excel files\n",
    "excel_files = glob.glob(\"*_extracted.xlsx\")\n",
    "\n",
    "if excel_files:\n",
    "    print(f\"Found {len(excel_files)} generated Excel files:\\n\")\n",
    "    \n",
    "    for excel_file in excel_files:\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"File: {excel_file}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            excel_data = pd.ExcelFile(excel_file)\n",
    "            print(f\"Contains {len(excel_data.sheet_names)} sheets:\")\n",
    "            \n",
    "            for sheet_name in excel_data.sheet_names[:5]:  # Show first 5 sheets\n",
    "                df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "                print(f\"\\n  {sheet_name}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "                if len(df.columns) > 0:\n",
    "                    print(f\"  Columns: {list(df.columns)[:5]}...\")  # Show first 5 columns\n",
    "                \n",
    "                # Show first row if data exists\n",
    "                if len(df) > 0:\n",
    "                    print(f\"  Sample data: {df.iloc[0].tolist()[:3]}...\")  # First 3 cells\n",
    "            \n",
    "            if len(excel_data.sheet_names) > 5:\n",
    "                print(f\"\\n  ... and {len(excel_data.sheet_names) - 5} more sheets\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {excel_file}: {e}\")\n",
    "        \n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(\"No Excel files with '_extracted.xlsx' suffix found.\")\n",
    "    print(\"Please run the batch processing cell above first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basangdata12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vincent": {
   "sessionId": "8c50670b7e22575f7a4bac27_2025-07-24T09-39-01-815Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
