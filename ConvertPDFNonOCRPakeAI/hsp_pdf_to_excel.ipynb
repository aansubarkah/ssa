{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "594c2"
   },
   "source": [
    "# Convert HSP PDF Tables to Excel\n",
    "\n",
    "This notebook processes HSP.pdf page by page, extracts tables using Google Vision API, and saves each page as a separate sheet in Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "6bb94"
   },
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "1. Install required packages if not already installed\n",
    "2. Set your Google API key\n",
    "3. Configure the prompt for table extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellUniqueIdByVincent": "92454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-genai\n",
      "  Downloading google_genai-1.27.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (4.67.1)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from google-genai) (2.37.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from google-genai) (2.10.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from google-genai) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from google-genai) (8.2.3)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from google-genai) (4.12.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (1.26.18)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\aansubarkah\\anaconda3\\envs\\basangdata12\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.5.1)\n",
      "Downloading google_genai-1.27.0-py3-none-any.whl (218 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Installing collected packages: websockets, anyio, google-genai\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 12.0\n",
      "    Uninstalling websockets-12.0:\n",
      "      Successfully uninstalled websockets-12.0\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.3.0\n",
      "    Uninstalling anyio-4.3.0:\n",
      "      Successfully uninstalled anyio-4.3.0\n",
      "Successfully installed anyio-4.9.0 google-genai-1.27.0 websockets-15.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mistralai 1.2.5 requires httpx<0.28.0,>=0.27.0, but you have httpx 0.28.1 which is incompatible.\n",
      "ollama 0.4.4 requires httpx<0.28.0,>=0.27.0, but you have httpx 0.28.1 which is incompatible.\n",
      "pyppeteer 2.0.0 requires websockets<11.0,>=10.0, but you have websockets 15.0.1 which is incompatible.\n",
      "unstructured-client 0.28.1 requires pydantic<2.10.0,>=2.9.2, but you have pydantic 2.10.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install google-genai pdf2image pillow pandas openpyxl tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "e9cfe"
   },
   "source": [
    "## API Key Configuration\n",
    "\n",
    "**IMPORTANT:** Replace the API_KEY below with your actual key from https://aistudio.google.com/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellUniqueIdByVincent": "4540e"
   },
   "outputs": [],
   "source": [
    "API_KEY = 'AIzaSyDBhCAMcISchXzLzkyWN3uI_ZvNKBDEP6Q'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "9fd5b"
   },
   "source": [
    "## Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellUniqueIdByVincent": "35244"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "from tqdm.notebook import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Any\n",
    "\n",
    "# Initialize the client\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "83d1d"
   },
   "source": [
    "## Define Data Models and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellUniqueIdByVincent": "45b07"
   },
   "outputs": [],
   "source": [
    "# Define the data model for table rows\n",
    "class TableRow(BaseModel):\n",
    "    row_data: List[str]  # Each cell in the row as a string\n",
    "\n",
    "class TableData(BaseModel):\n",
    "    headers: List[str]  # Column headers\n",
    "    rows: List[TableRow]  # Table rows\n",
    "    page_info: str  # Any additional page information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellUniqueIdByVincent": "c3db9"
   },
   "outputs": [],
   "source": [
    "# Prompt for table extraction\n",
    "TABLE_EXTRACTION_PROMPT = '''\n",
    "Analyze this image and extract all table data found on this page.\n",
    "\n",
    "Please:\n",
    "1. Identify all tables on the page\n",
    "2. Extract column headers (if any)\n",
    "3. Extract all row data, preserving the structure\n",
    "4. If there are multiple tables, combine them or note their separation\n",
    "5. Include any relevant page information (title, date, etc.)\n",
    "\n",
    "Return the data in the specified JSON format with:\n",
    "- headers: list of column headers\n",
    "- rows: list of table rows, where each row contains a list of cell values\n",
    "- page_info: any additional context about the page\n",
    "\n",
    "If no table is found, return empty headers and rows arrays.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "cdb89"
   },
   "source": [
    "## PDF Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellUniqueIdByVincent": "8eb20"
   },
   "outputs": [],
   "source": [
    "def convert_pdf_to_images(pdf_path, dpi=200):\n",
    "    \"\"\"\n",
    "    Convert PDF pages to images\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        dpi: Resolution for conversion (higher = better quality, larger file)\n",
    "    \n",
    "    Returns:\n",
    "        List of PIL Image objects\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Converting PDF to images with DPI: {dpi}\")\n",
    "        images = convert_from_path(pdf_path, dpi=dpi)\n",
    "        print(f\"Successfully converted {len(images)} pages\")\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting PDF: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellUniqueIdByVincent": "0869f"
   },
   "outputs": [],
   "source": [
    "def extract_table_from_image(image, page_num):\n",
    "    \"\"\"\n",
    "    Extract table data from a single page image using Google Vision API\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        page_num: Page number for reference\n",
    "    \n",
    "    Returns:\n",
    "        TableData object or None if extraction fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert PIL image to bytes\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        image.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr = img_byte_arr.getvalue()\n",
    "        \n",
    "        # Call Google Vision API\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash-lite',\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.2,\n",
    "                response_mime_type='application/json',\n",
    "                response_schema=TableData\n",
    "            ),\n",
    "            contents=[\n",
    "                types.Part.from_bytes(\n",
    "                    data=img_byte_arr,\n",
    "                    mime_type='image/png'\n",
    "                ),\n",
    "                TABLE_EXTRACTION_PROMPT\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        table_data: TableData = response.parsed\n",
    "        print(f\"Page {page_num}: Extracted {len(table_data.rows)} rows\")\n",
    "        return table_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting table from page {page_num}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellUniqueIdByVincent": "9f4f2"
   },
   "outputs": [],
   "source": [
    "def table_data_to_dataframe(table_data, page_num):\n",
    "    \"\"\"\n",
    "    Convert TableData to pandas DataFrame\n",
    "    \n",
    "    Args:\n",
    "        table_data: TableData object\n",
    "        page_num: Page number for reference\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame or None if conversion fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not table_data or not table_data.rows:\n",
    "            print(f\"Page {page_num}: No table data found\")\n",
    "            return None\n",
    "        \n",
    "        # Convert rows to list of lists\n",
    "        rows_data = [row.row_data for row in table_data.rows]\n",
    "        \n",
    "        # Create DataFrame\n",
    "        if table_data.headers:\n",
    "            df = pd.DataFrame(rows_data, columns=table_data.headers)\n",
    "        else:\n",
    "            df = pd.DataFrame(rows_data)\n",
    "        \n",
    "        # Add page information\n",
    "        df['page_number'] = page_num\n",
    "        if table_data.page_info:\n",
    "            df['page_info'] = table_data.page_info\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error converting table data to DataFrame for page {page_num}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "ec57f"
   },
   "source": [
    "## Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellUniqueIdByVincent": "f949c"
   },
   "outputs": [],
   "source": [
    "def process_pdf_to_excel(pdf_path, output_path, dpi=200):\n",
    "    \"\"\"\n",
    "    Process PDF and create Excel file with separate sheets for each page\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        output_path: Path for the output Excel file\n",
    "        dpi: Resolution for PDF to image conversion\n",
    "    \"\"\"\n",
    "    print(f\"Starting processing of {pdf_path}\")\n",
    "    \n",
    "    # Convert PDF to images\n",
    "    images = convert_pdf_to_images(pdf_path, dpi)\n",
    "    if not images:\n",
    "        print(\"Failed to convert PDF to images\")\n",
    "        return\n",
    "    \n",
    "    # Process each page\n",
    "    all_dataframes = {}\n",
    "    \n",
    "    for i, image in enumerate(tqdm(images, desc=\"Processing pages\")):\n",
    "        page_num = i + 1\n",
    "        print(f\"\\nProcessing page {page_num}...\")\n",
    "        \n",
    "        # Extract table data\n",
    "        table_data = extract_table_from_image(image, page_num)\n",
    "        \n",
    "        if table_data:\n",
    "            # Convert to DataFrame\n",
    "            df = table_data_to_dataframe(table_data, page_num)\n",
    "            \n",
    "            if df is not None and not df.empty:\n",
    "                sheet_name = f\"Page_{page_num}\"\n",
    "                all_dataframes[sheet_name] = df\n",
    "                print(f\"Page {page_num}: Added {len(df)} rows to sheet '{sheet_name}'\")\n",
    "            else:\n",
    "                print(f\"Page {page_num}: No valid data extracted\")\n",
    "        else:\n",
    "            print(f\"Page {page_num}: Failed to extract table data\")\n",
    "    \n",
    "    # Save to Excel\n",
    "    if all_dataframes:\n",
    "        print(f\"\\nSaving {len(all_dataframes)} sheets to {output_path}\")\n",
    "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "            for sheet_name, df in all_dataframes.items():\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"Successfully saved Excel file: {output_path}\")\n",
    "    else:\n",
    "        print(\"No data extracted from any page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "9f43c"
   },
   "source": [
    "## Execute Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellUniqueIdByVincent": "00a68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PDF file: HSP.pdf\n",
      "Starting processing of HSP.pdf\n",
      "Converting PDF to images with DPI: 200\n",
      "Successfully converted 38 pages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c3c3f2c6f444958be0f154b251fa5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing pages:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing page 1...\n",
      "Page 1: Extracted 0 rows\n",
      "Page 1: No table data found\n",
      "Page 1: No valid data extracted\n",
      "\n",
      "Processing page 2...\n",
      "Page 2: Extracted 0 rows\n",
      "Page 2: No table data found\n",
      "Page 2: No valid data extracted\n",
      "\n",
      "Processing page 3...\n",
      "Page 3: Extracted 1 rows\n",
      "Page 3: Added 1 rows to sheet 'Page_3'\n",
      "\n",
      "Processing page 4...\n",
      "Page 4: Extracted 15 rows\n",
      "Page 4: Added 15 rows to sheet 'Page_4'\n",
      "\n",
      "Processing page 5...\n",
      "Page 5: Extracted 79 rows\n",
      "Page 5: Added 79 rows to sheet 'Page_5'\n",
      "\n",
      "Processing page 6...\n",
      "Page 6: Extracted 86 rows\n",
      "Page 6: Added 86 rows to sheet 'Page_6'\n",
      "\n",
      "Processing page 7...\n",
      "Page 7: Extracted 84 rows\n",
      "Page 7: Added 84 rows to sheet 'Page_7'\n",
      "\n",
      "Processing page 8...\n",
      "Page 8: Extracted 83 rows\n",
      "Page 8: Added 83 rows to sheet 'Page_8'\n",
      "\n",
      "Processing page 9...\n",
      "Page 9: Extracted 68 rows\n",
      "Page 9: Added 68 rows to sheet 'Page_9'\n",
      "\n",
      "Processing page 10...\n",
      "Page 10: Extracted 84 rows\n",
      "Page 10: Added 84 rows to sheet 'Page_10'\n",
      "\n",
      "Processing page 11...\n",
      "Page 11: Extracted 42 rows\n",
      "Page 11: Added 42 rows to sheet 'Page_11'\n",
      "\n",
      "Processing page 12...\n",
      "Page 12: Extracted 52 rows\n",
      "Page 12: Added 52 rows to sheet 'Page_12'\n",
      "\n",
      "Processing page 13...\n",
      "Page 13: Extracted 78 rows\n",
      "Page 13: Added 78 rows to sheet 'Page_13'\n",
      "\n",
      "Processing page 14...\n",
      "Page 14: Extracted 80 rows\n",
      "Page 14: Added 80 rows to sheet 'Page_14'\n",
      "\n",
      "Processing page 15...\n",
      "Page 15: Extracted 81 rows\n",
      "Page 15: Added 81 rows to sheet 'Page_15'\n",
      "\n",
      "Processing page 16...\n",
      "Page 16: Extracted 67 rows\n",
      "Page 16: Added 67 rows to sheet 'Page_16'\n",
      "\n",
      "Processing page 17...\n",
      "Page 17: Extracted 75 rows\n",
      "Page 17: Added 75 rows to sheet 'Page_17'\n",
      "\n",
      "Processing page 18...\n",
      "Page 18: Extracted 77 rows\n",
      "Page 18: Added 77 rows to sheet 'Page_18'\n",
      "\n",
      "Processing page 19...\n",
      "Page 19: Extracted 78 rows\n",
      "Page 19: Added 78 rows to sheet 'Page_19'\n",
      "\n",
      "Processing page 20...\n",
      "Page 20: Extracted 76 rows\n",
      "Page 20: Added 76 rows to sheet 'Page_20'\n",
      "\n",
      "Processing page 21...\n",
      "Page 21: Extracted 74 rows\n",
      "Page 21: Added 74 rows to sheet 'Page_21'\n",
      "\n",
      "Processing page 22...\n",
      "Page 22: Extracted 72 rows\n",
      "Page 22: Added 72 rows to sheet 'Page_22'\n",
      "\n",
      "Processing page 23...\n",
      "Page 23: Extracted 71 rows\n",
      "Page 23: Added 71 rows to sheet 'Page_23'\n",
      "\n",
      "Processing page 24...\n",
      "Page 24: Extracted 59 rows\n",
      "Page 24: Added 59 rows to sheet 'Page_24'\n",
      "\n",
      "Processing page 25...\n",
      "Page 25: Extracted 67 rows\n",
      "Page 25: Added 67 rows to sheet 'Page_25'\n",
      "\n",
      "Processing page 26...\n",
      "Page 26: Extracted 45 rows\n",
      "Error converting table data to DataFrame for page 26: 6 columns passed, passed data had 4 columns\n",
      "Page 26: No valid data extracted\n",
      "\n",
      "Processing page 27...\n",
      "Page 27: Extracted 65 rows\n",
      "Page 27: Added 65 rows to sheet 'Page_27'\n",
      "\n",
      "Processing page 28...\n",
      "Page 28: Extracted 70 rows\n",
      "Page 28: Added 70 rows to sheet 'Page_28'\n",
      "\n",
      "Processing page 29...\n",
      "Page 29: Extracted 69 rows\n",
      "Page 29: Added 69 rows to sheet 'Page_29'\n",
      "\n",
      "Processing page 30...\n",
      "Page 30: Extracted 69 rows\n",
      "Page 30: Added 69 rows to sheet 'Page_30'\n",
      "\n",
      "Processing page 31...\n",
      "Page 31: Extracted 68 rows\n",
      "Page 31: Added 68 rows to sheet 'Page_31'\n",
      "\n",
      "Processing page 32...\n",
      "Page 32: Extracted 67 rows\n",
      "Page 32: Added 67 rows to sheet 'Page_32'\n",
      "\n",
      "Processing page 33...\n",
      "Page 33: Extracted 67 rows\n",
      "Page 33: Added 67 rows to sheet 'Page_33'\n",
      "\n",
      "Processing page 34...\n",
      "Page 34: Extracted 16 rows\n",
      "Page 34: Added 16 rows to sheet 'Page_34'\n",
      "\n",
      "Processing page 35...\n",
      "Page 35: Extracted 36 rows\n",
      "Page 35: Added 36 rows to sheet 'Page_35'\n",
      "\n",
      "Processing page 36...\n",
      "Page 36: Extracted 41 rows\n",
      "Page 36: Added 41 rows to sheet 'Page_36'\n",
      "\n",
      "Processing page 37...\n",
      "Page 37: Extracted 38 rows\n",
      "Page 37: Added 38 rows to sheet 'Page_37'\n",
      "\n",
      "Processing page 38...\n",
      "Page 38: Extracted 8 rows\n",
      "Page 38: Added 8 rows to sheet 'Page_38'\n",
      "\n",
      "Saving 35 sheets to HSP_tables.xlsx\n",
      "Successfully saved Excel file: HSP_tables.xlsx\n",
      "\n",
      "Processing complete! Check HSP_tables.xlsx for results.\n"
     ]
    }
   ],
   "source": [
    "# Set file paths\n",
    "pdf_file = \"HSP.pdf\"\n",
    "output_file = \"HSP_tables.xlsx\"\n",
    "\n",
    "# Check if PDF file exists\n",
    "if os.path.exists(pdf_file):\n",
    "    print(f\"Found PDF file: {pdf_file}\")\n",
    "    \n",
    "    # Process the PDF\n",
    "    process_pdf_to_excel(pdf_file, output_file, dpi=200)\n",
    "    \n",
    "    print(f\"\\nProcessing complete! Check {output_file} for results.\")\n",
    "else:\n",
    "    print(f\"PDF file not found: {pdf_file}\")\n",
    "    print(\"Please make sure HSP.pdf is in the same directory as this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "38de0"
   },
   "source": [
    "## Optional: Preview Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "221b7"
   },
   "outputs": [],
   "source": [
    "# Optional: Load and preview the generated Excel file\n",
    "if os.path.exists(output_file):\n",
    "    excel_file = pd.ExcelFile(output_file)\n",
    "    print(f\"Excel file contains {len(excel_file.sheet_names)} sheets:\")\n",
    "    \n",
    "    for sheet_name in excel_file.sheet_names:\n",
    "        df = pd.read_excel(output_file, sheet_name=sheet_name)\n",
    "        print(f\"\\n{sheet_name}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Show first few rows\n",
    "        if len(df) > 0:\n",
    "            print(\"First 3 rows:\")\n",
    "            print(df.head(3))\n",
    "else:\n",
    "    print(\"Output file not found. Please run the processing cell above first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basangdata12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vincent": {
   "sessionId": "9b6ae88288ca020ccc68658a_2025-07-24T09-00-32-543Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
